{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_countries = ['australia', 'austria', 'belgium', 'brazil', 'canada', 'chile', 'china', 'czechia', 'denmark', 'estonia', 'finland', 'france', 'germany', 'greece', 'hungary', 'iceland', 'india', 'ireland', 'israel', 'italy', 'japan', 'korea', 'latvia', 'lithuania', 'luxembourg', 'mexico', 'netherlands', 'new zealand', 'norway', 'poland', 'portugal', 'slovakia', 'slovenia', 'spain', 'sweden', 'switzerland', 'turkey', 'united kingdom', 'usa', 'rep. of korea']\n",
    "#breiger_commodity = [0, 2, 3, 6]\n",
    "orig_countries = ['austria', 'belgium', 'belgium-luxembourg', 'canada', 'denmark', 'france', 'germany', 'greece', 'iceland', 'ireland', 'luxembourg','netherlands', 'norway', 'portugal', 'spain', 'sweden', 'switzerland', 'turkey', 'united kingdom', 'usa', 'italy', 'japan', 'finland', 'australia', 'israel', 'yugoslavia', 'usa (before 1981)', 'fmr fed. rep. of germany', 'fmr yugoslavia']\n",
    "\n",
    "columns = ['Classification', 'Period', 'Period Desc.', 'Aggregate Level',\n",
    "       'Is Leaf Code','Reporter Code', 'Reporter ISO', 'Partner Code', 'Partner ISO',\n",
    "       '2nd Partner Code', '2nd Partner', '2nd Partner ISO',\n",
    "       'Customs Proc. Code', 'Customs', 'Mode of Transport Code', 'Trade Flow Code', \n",
    "       'Mode of Transport', 'Qty Unit Code',\n",
    "       'Qty Unit', 'Qty', 'Alt Qty Unit Code', 'Alt Qty Unit', 'Alt Qty',\n",
    "       'Netweight (kg)', 'Gross weight (kg)', 'CIF Trade Value (US$)', 'FOB Trade Value (US$)', 'Flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all files in 2008\n",
    "path2007 = r'C:\\Users\\Dhruval\\Documents\\MACSS\\2019_Autumn\\Network Analysis\\NetworkAnalysis_Project\\Raw Data 2007'\n",
    "path2008 = r'C:\\Users\\Dhruval\\Documents\\MACSS\\2019_Autumn\\Network Analysis\\NetworkAnalysis_Project\\Raw Data 2008' # use your path\n",
    "path2013 = r'C:\\Users\\Dhruval\\Documents\\MACSS\\2019_Autumn\\Network Analysis\\NetworkAnalysis_Project\\Raw Data 2013'\n",
    "path2018 = r'C:\\Users\\Dhruval\\Documents\\MACSS\\2019_Autumn\\Network Analysis\\NetworkAnalysis_Project\\Raw Data 2018'\n",
    "path1972 = r'C:\\Users\\Dhruval\\Documents\\MACSS\\2019_Autumn\\Network Analysis\\NetworkAnalysis_Project\\Raw Data 1972'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to combine data files\n",
    "\n",
    "def combine_data(path):\n",
    "    all_files = glob.glob(path + \"/*.csv\")\n",
    "    \n",
    "    li = []\n",
    "\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        li.append(df)\n",
    "\n",
    "    data = pd.concat(li, axis=0, ignore_index=True)\n",
    "    return data\n",
    "\n",
    "def clean_data(data):\n",
    "    data.drop(columns=columns, inplace=True) #drop any column that is not needed\n",
    "    \n",
    "    #lower the strings\n",
    "    data['Reporter'] = data['Reporter'].str.lower()\n",
    "    data['Partner'] = data['Partner'].str.lower()\n",
    "    data['Trade Flow'] = data['Trade Flow'].str.lower()\n",
    "\n",
    "    #Remove all re-imports and re-exports\n",
    "    #data = data.drop(data[data['Trade Flow'] == 're-import'].index)\n",
    "    #data = data.drop(data[data['Trade Flow'] == 're-export'].index)\n",
    "    \n",
    "    #Filter out trade within nation\n",
    "    data = data[data['Reporter'] != data['Partner']]\n",
    "    \n",
    "    #Remove partner countries that are not in the list\n",
    "    data = data[data['Partner'].isin(oecd_countries)]\n",
    "    \n",
    "    #Remove reporter countries that are not in the list\n",
    "    data = data[data['Reporter'].isin(oecd_countries)]\n",
    "\n",
    "    return data\n",
    "\n",
    "def save_data(path, file_name):\n",
    "    data = combine_data(path)\n",
    "    dataframe = clean_data(data)\n",
    "    file = r'C:\\\\Users\\\\Dhruval\\\\Documents\\\\MACSS\\\\2019_Autumn\\\\Network Analysis\\\\NetworkAnalysis_Project\\\\Data\\'' + file_name + '.csv'\n",
    "    #file = r'C:\\Users\\Dhruval\\Documents\\MACSS\\2019_Autumn\\Network Analysis\\NetworkAnalysis_Project\\Data\\'' + file_name + '.csv'\n",
    "    dataframe.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_1972(data):\n",
    "    data.drop(columns=columns, inplace=True) #drop any column that is not needed\n",
    "    \n",
    "    #lower the strings\n",
    "    data['Reporter'] = data['Reporter'].str.lower()\n",
    "    data['Partner'] = data['Partner'].str.lower()\n",
    "    data['Trade Flow'] = data['Trade Flow'].str.lower()\n",
    "\n",
    "    #Remove all re-imports and re-exports\n",
    "    #data = data.drop(data[data['Trade Flow'] == 're-import'].index)\n",
    "    #data = data.drop(data[data['Trade Flow'] == 're-export'].index)\n",
    "    \n",
    "    #Filter out trade within nation\n",
    "    data = data[data['Reporter'] != data['Partner']]\n",
    "    \n",
    "    #Remove partner countries that are not in the list\n",
    "    data = data[data['Partner'].isin(orig_countries)]\n",
    "    \n",
    "    #Remove reporter countries that are not in the list\n",
    "    data = data[data['Reporter'].isin(orig_countries)]\n",
    "       \n",
    "    data.replace(to_replace = 'usa (before 1981)', value ='usa', inplace=True)\n",
    "    data.replace(to_replace = 'fmr fed. rep. of germany', value = 'germany', inplace=True)\n",
    "    data.replace(to_replace = 'fmr yugoslavia', value = 'yugoslavia', inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def save_1972(path, file_name):\n",
    "    data = combine_data(path)\n",
    "    dataframe = clean_1972(data)\n",
    "    file = r'C:\\\\Users\\\\Dhruval\\\\Documents\\\\MACSS\\\\2019_Autumn\\\\Network Analysis\\\\NetworkAnalysis_Project\\\\Data\\'' + file_name + '.csv'\n",
    "    #file = r'C:\\Users\\Dhruval\\Documents\\MACSS\\2019_Autumn\\Network Analysis\\NetworkAnalysis_Project\\Data\\'' + file_name + '.csv'\n",
    "    dataframe.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine to create Final DataSets\n",
    "save_data(path2007, 'data2007')\n",
    "save_data(path2008, 'data2008')\n",
    "save_data(path2013, 'data2013')\n",
    "save_data(path2018, 'data2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_1972(path1972, 'data1972')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "data2007 = pd.read_csv(r'C:\\Users\\Dhruval\\Documents\\MACSS\\2019_Autumn\\Network Analysis\\NetworkAnalysis_Project\\Data\\'data2007.csv')\n",
    "data2008 = pd.read_csv(r'C:\\Users\\Dhruval\\Documents\\MACSS\\2019_Autumn\\Network Analysis\\NetworkAnalysis_Project\\Data\\'data2008.csv')\n",
    "data2013 = pd.read_csv(r'C:\\Users\\Dhruval\\Documents\\MACSS\\2019_Autumn\\Network Analysis\\NetworkAnalysis_Project\\Data\\'data2013.csv')\n",
    "data2018 = pd.read_csv(r'C:\\Users\\Dhruval\\Documents\\MACSS\\2019_Autumn\\Network Analysis\\NetworkAnalysis_Project\\Data\\'data2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1972 = pd.read_csv(r'C:\\Users\\Dhruval\\Documents\\MACSS\\2019_Autumn\\Network Analysis\\NetworkAnalysis_Project\\Data\\'data1972.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Create Export square matrix\n",
    "\n",
    "def export_square(data, filename, commodity_code):\n",
    "    data_export = data[data['Trade Flow'] == 'export']\n",
    "    com_data = data_export[data_export['Commodity Code'] == commodity_code]\n",
    "    \n",
    "    ex_matrix = com_data.groupby(['Reporter', 'Partner'],as_index = False)['Trade Value (US$)'].sum().pivot('Reporter', 'Partner').fillna(0)\n",
    "    ex_matrix.columns = ex_matrix.columns.droplevel(0)\n",
    "    del ex_matrix.index.name\n",
    "    \n",
    "    #Save to File\n",
    "    file = r'C:\\Users\\Dhruval\\Documents\\MACSS\\2019_Autumn\\Network Analysis\\NetworkAnalysis_Project\\Data\\'' + filename + '.csv'\n",
    "    ex_matrix.to_csv(file, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Create IMport - Export square matrix\n",
    "\n",
    "def square(data, filename, commodity_code):\n",
    "    #com_data = data[data['Commodity Code'] == commodity_code]\n",
    "    \n",
    "    ex_matrix = data.groupby(['Reporter', 'Partner'],as_index = False)['Trade Value (US$)'].sum().pivot('Reporter', 'Partner').fillna(0)\n",
    "    ex_matrix.columns = ex_matrix.columns.droplevel(0)\n",
    "    del ex_matrix.index.name\n",
    "    \n",
    "    #Save to File\n",
    "    file = r'C:\\Users\\Dhruval\\Documents\\MACSS\\2019_Autumn\\Network Analysis\\NetworkAnalysis_Project\\Data\\'' + filename + '.csv'\n",
    "    ex_matrix.to_csv(file, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018\n",
    "export_square(data2018, 'agr2018', 0)\n",
    "export_square(data2018, 'raw2018', 2)\n",
    "export_square(data2018, 'man2018', 3)\n",
    "export_square(data2018, 'enr2018', 6)\n",
    "\n",
    "#2013\n",
    "export_square(data2013, 'agr2013', 0)\n",
    "export_square(data2013, 'raw2013', 2)\n",
    "export_square(data2013, 'man2013', 3)\n",
    "export_square(data2013, 'enr2013', 6)\n",
    "\n",
    "#2008\n",
    "export_square(data2008, 'agr2008', 0)\n",
    "export_square(data2008, 'raw2008', 2)\n",
    "export_square(data2008, 'man2008', 3)\n",
    "export_square(data2008, 'enr2008', 6)\n",
    "\n",
    "#2003\n",
    "export_square(data2007, 'agr2007', 0)\n",
    "export_square(data2007, 'raw2007', 2)\n",
    "export_square(data2007, 'man2007', 3)\n",
    "export_square(data2007, 'enr2007', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orig_square(data, filename, commodity_code):\n",
    "    #Remove partner countries that are not in the original list\n",
    "    data = data[data['Partner'].isin(orig_countries)]\n",
    "    \n",
    "    #Remove reporter countries that are not in the original list\n",
    "    data = data[data['Reporter'].isin(orig_countries)]\n",
    "    \n",
    "    com_data = data_export[data_export['Commodity Code'] == commodity_code]\n",
    "    \n",
    "    ex_matrix = com_data.groupby(['Reporter', 'Partner'],as_index = False)['Trade Value (US$)'].sum().pivot('Reporter', 'Partner').fillna(0)\n",
    "    ex_matrix.columns = ex_matrix.columns.droplevel(0)\n",
    "    del ex_matrix.index.name\n",
    "    \n",
    "    #Save to File\n",
    "    file = r'C:\\Users\\Dhruval\\Documents\\MACSS\\2019_Autumn\\Network Analysis\\NetworkAnalysis_Project\\Data\\'' + filename + '.csv'\n",
    "    ex_matrix.to_csv(file, index=True)\n",
    "    \n",
    "def orig_export_square(data, filename, commodity_code):\n",
    "    #Remove partner countries that are not in the original list\n",
    "    data = data[data['Partner'].isin(orig_countries)]\n",
    "    \n",
    "    #Remove reporter countries that are not in the original list\n",
    "    data = data[data['Reporter'].isin(orig_countries)]\n",
    "    \n",
    "    data_export = data[data['Trade Flow'] == 'export']\n",
    "    com_data = data_export[data_export['Commodity Code'] == commodity_code]\n",
    "    \n",
    "    ex_matrix = com_data.groupby(['Reporter', 'Partner'],as_index = False)['Trade Value (US$)'].sum().pivot('Reporter', 'Partner').fillna(0)\n",
    "    ex_matrix.columns = ex_matrix.columns.droplevel(0)\n",
    "    del ex_matrix.index.name\n",
    "    \n",
    "    #Save to File\n",
    "    file = r'C:\\Users\\Dhruval\\Documents\\MACSS\\2019_Autumn\\Network Analysis\\NetworkAnalysis_Project\\Data\\'' + filename + '.csv'\n",
    "    ex_matrix.to_csv(file, index=True)\n",
    "    \n",
    "def orig_import_square(data, filename, commodity_code):\n",
    "    data = data[data['Partner'].isin(orig_countries)]\n",
    "    \n",
    "    #Remove reporter countries that are not in the original list\n",
    "    data = data[data['Reporter'].isin(orig_countries)]\n",
    "    \n",
    "    data_import = data[data['Trade Flow'] == 'import']\n",
    "    com_data = data_import[data_import['Commodity Code'] == commodity_code]\n",
    "    \n",
    "    im_matrix = com_data.groupby(['Reporter', 'Partner'],as_index = False)['Trade Value (US$)'].sum().pivot('Reporter', 'Partner').fillna(0)\n",
    "    im_matrix.columns = im_matrix.columns.droplevel(0)\n",
    "    del im_matrix.index.name\n",
    "    \n",
    "    #Save to File\n",
    "    file = r'C:\\Users\\Dhruval\\Documents\\MACSS\\2019_Autumn\\Network Analysis\\NetworkAnalysis_Project\\Data\\'' + filename + '.csv'\n",
    "    im_matrix.to_csv(file, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018\n",
    "orig_export_square(data2018, 'o_agr2018', 0)\n",
    "orig_export_square(data2018, 'o_raw2018', 2)\n",
    "orig_export_square(data2018, 'o_man2018', 3)\n",
    "orig_export_square(data2018, 'o_enr2018', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Create Import square matrix\n",
    "\n",
    "def import_square(data, filename, commodity_code):\n",
    "    data_import = data[data['Trade Flow'] == 'import']\n",
    "    com_data = data_import[data_import['Commodity Code'] == commodity_code]\n",
    "    \n",
    "    im_matrix = com_data.groupby(['Reporter', 'Partner'],as_index = False)['Trade Value (US$)'].sum().pivot('Reporter', 'Partner').fillna(0)\n",
    "    im_matrix.columns = im_matrix.columns.droplevel(0)\n",
    "    del im_matrix.index.name\n",
    "    \n",
    "    #Save to File\n",
    "    file = r'C:\\Users\\Dhruval\\Documents\\MACSS\\2019_Autumn\\Network Analysis\\NetworkAnalysis_Project\\Data\\'' + filename + '.csv'\n",
    "    im_matrix.to_csv(file, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018\n",
    "import_square(data2018, 'im_agr2018', 0)\n",
    "import_square(data2018, 'im_raw2018', 2)\n",
    "import_square(data2018, 'im_man2018', 3)\n",
    "import_square(data2018, 'im_enr2018', 6)\n",
    "\n",
    "#2013\n",
    "import_square(data2013, 'im_agr2013', 0)\n",
    "import_square(data2013, 'im_raw2013', 2)\n",
    "import_square(data2013, 'im_man2013', 3)\n",
    "import_square(data2013, 'im_enr2013', 6)\n",
    "\n",
    "#2008\n",
    "import_square(data2008, 'im_agr2008', 0)\n",
    "import_square(data2008, 'im_raw2008', 2)\n",
    "import_square(data2008, 'im_man2008', 3)\n",
    "import_square(data2008, 'im_enr2008', 6)\n",
    "\n",
    "#2003\n",
    "import_square(data2007, 'im_agr2007', 0)\n",
    "import_square(data2007, 'im_raw2007', 2)\n",
    "import_square(data2007, 'im_man2007', 3)\n",
    "import_square(data2007, 'im_enr2007', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1972\n",
    "orig_export_square(data1972, 'agr1972', 0)\n",
    "orig_export_square(data1972, 'raw1972', 2)\n",
    "orig_export_square(data1972, 'man1972', 3)\n",
    "orig_export_square(data1972, 'enr1972', 6)\n",
    "\n",
    "#1972\n",
    "orig_import_square(data1972, 'im_agr1972', 0)\n",
    "orig_import_square(data1972, 'im_raw1972', 2)\n",
    "orig_import_square(data1972, 'im_man1972', 3)\n",
    "orig_import_square(data1972, 'im_enr1972', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1972\n",
    "square(data1972, 'ie_all1972', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
